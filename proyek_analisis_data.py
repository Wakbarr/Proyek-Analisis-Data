# -*- coding: utf-8 -*-
"""Proyek Analisis Data.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ug4Ox4qIFDSo1koFA0XiNJE-ce12rECy

# Proyek Analisis Data: E-Commerce Public Dataset
- **Nama:** Akbar Widianto
- **Email:** wdntoakbar@gmail.com
- **ID Dicoding:** wakbarr

## Menentukan Pertanyaan Bisnis

- Produk manakah yang paling banyak terjual dan paling sedikit terjual?
- Bagaimana performa penjualan dan pendapatan dalam beberapa bulan terakhir?

## Import Semua Packages/Library yang Digunakan
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')
import urllib
!pip install unidecode
import unidecode
import matplotlib.image as mpimg

"""## Data Wrangling

### Gathering Data
"""

customer_df = pd.read_csv('https://raw.githubusercontent.com/Wakbarr/Proyek-Analisis-Data/refs/heads/main/data/customers_dataset.csv')
customer_df.head()

geolocation_df = pd.read_csv('https://raw.githubusercontent.com/Wakbarr/Proyek-Analisis-Data/refs/heads/main/data/geolocation_dataset.csv')
geolocation_df.head()

order_item_df = pd.read_csv('https://raw.githubusercontent.com/nurhadimeilana05/Proyek-Analisis-Data-Dicoding/main/data/order_items_dataset.csv')
order_item_df.head()

order_payment_df = pd.read_csv('https://raw.githubusercontent.com/Wakbarr/Proyek-Analisis-Data/refs/heads/main/data/order_payments_dataset.csv')
order_payment_df.head()

order_review_df = pd.read_csv('https://raw.githubusercontent.com/Wakbarr/Proyek-Analisis-Data/refs/heads/main/data/order_reviews_dataset.csv')
order_review_df.head()

order_df = pd.read_csv('https://raw.githubusercontent.com/Wakbarr/Proyek-Analisis-Data/refs/heads/main/data/orders_dataset.csv')
order_df.head()

product_category_df = pd.read_csv('https://raw.githubusercontent.com/Wakbarr/Proyek-Analisis-Data/refs/heads/main/data/product_category_name_translation.csv')
product_category_df.head()

product_df = pd.read_csv('https://raw.githubusercontent.com/Wakbarr/Proyek-Analisis-Data/refs/heads/main/data/products_dataset.csv')
product_df.head()

seller_df = pd.read_csv('https://raw.githubusercontent.com/Wakbarr/Proyek-Analisis-Data/refs/heads/main/data/sellers_dataset.csv')
seller_df.head()

"""**Insight:**
- Dataset tersebut merupakan dataset dari salah satu E-Commerce yang ada di Brazil
- Dari dataset E-Commerce tersebut terdapat 9 tabel yang akan digunakan untuk analisis

### Assessing Data
"""

print('\nInformasi Tabel:\n')
customer_df.info()

print('\nJumlah Missing Value:\n')
print(customer_df.isna().sum())

print('\nJumlah Data Duplikat:\n')
print(customer_df.duplicated().sum())

print('\nRingkasan Statistik Deskriptif Data:\n')
customer_df.describe(include='all')

"""**Insight:**
- Untuk tipe data setiap atribut sudah benar
- Tidak ada missing value
- Tidak ada data duplikat

### Cleaning Data
"""

print('\nInformasi Tabel:\n')
geolocation_df.info()

print('\nJumlah Missing Value:\n')
print(geolocation_df.isna().sum())

print('\nJumlah Data Duplikat:\n')
print(geolocation_df.duplicated().sum())

print('\nRingkasan Statistik Deskriptif Data:\n')
geolocation_df.describe(include='all')

"""**Insight:**
- Untuk tipe data setiap atribut sudah benar
- Tidak ada missing value
- Terdapat 261831 data duplikat

## Exploratory Data Analysis (EDA)

### Explore ...
"""

print('\nInformasi Tabel:\n')
order_item_df.info()

print('\nJumlah Missing Value:\n')
print(order_item_df.isna().sum())

print('\nJumlah Data Duplikat:\n')
print(order_item_df.duplicated().sum())

print('\nRingkasan Statistik Deskriptif Data:\n')
order_item_df.describe(include='all')

"""**Insight:**
- Terdapat kesalahan tipe data pada atribut shipping_limit_date yang seharusnya datetime malah object
- Tidak ada missing value
- Tidak ada data duplikat

## Visualization & Explanatory Analysis

### Pertanyaan 1:
"""

print('\nInformasi Tabel:\n')
order_payment_df.info()

print('\nJumlah Missing Value:\n')
print(order_payment_df.isna().sum())

print('\nJumlah Data Duplikat:\n')
print(order_payment_df.duplicated().sum())

print('\nRingkasan Statistik Deskriptif Data:\n')
order_payment_df.describe(include='all')

"""### Pertanyaan 2:"""

print('\nInformasi Tabel:\n')
order_review_df.info()

print('\nJumlah Missing Value:\n')
print(order_review_df.isna().sum())

print('\nJumlah Data Duplikat:\n')
print(order_review_df.duplicated().sum())

print('\nRingkasan Statistik Deskriptif Data:\n')
order_review_df.describe(include='all')

print('\nInformasi Tabel:\n')
order_df.info()

print('\nJumlah Missing Value:\n')
print(order_df.isna().sum())

print('\nJumlah Data Duplikat:\n')
print(order_df.duplicated().sum())

print('\nRingkasan Statistik Deskriptif Data:\n')
order_df.describe(include='all')

print('\nInformasi Tabel:\n')
product_category_df.info()

print('\nJumlah Missing Value:\n')
print(product_category_df.isna().sum())

print('\nJumlah Data Duplikat:\n')
print(product_category_df.duplicated().sum())

print('\nRingkasan Statistik Deskriptif Data:\n')
product_category_df.describe(include='all')

print('\nInformasi Tabel:\n')
product_df.info()

print('\nJumlah Missing Value:\n')
print(product_df.isna().sum())

print('\nJumlah Data Duplikat:\n')
print(product_df.duplicated().sum())

print('\nRingkasan Statistik Deskriptif Data:\n')
product_df.describe(include='all')

print('\nInformasi Tabel:\n')
seller_df.info()

print('\nJumlah Missing Value:\n')
print(seller_df.isna().sum())

print('\nJumlah Data Duplikat:\n')
print(seller_df.duplicated().sum())

print('\nRingkasan Statistik Deskriptif Data:\n')
seller_df.describe(include='all')

geolocation_df = geolocation_df.drop_duplicates()
geolocation_df.duplicated().sum()

datetime_order_item = ["shipping_limit_date"]

for column in datetime_order_item:
  order_item_df[column] = pd.to_datetime(order_item_df[column])

order_item_df.info()

datetime_order_review = ["review_creation_date", "review_answer_timestamp"]

for column in datetime_order_review:
  order_review_df[column] = pd.to_datetime(order_review_df[column])

order_review_df.info()

order_review_df = order_review_df.fillna('no comment')
order_review_df.isna().sum()

datetime_order = ["order_purchase_timestamp","order_approved_at","order_delivered_carrier_date","order_delivered_customer_date","order_estimated_delivery_date"]

for column in datetime_order:
  order_df[column] = pd.to_datetime(order_df[column])

order_df.info()

product_df[product_df['product_category_name'].isna()]

product_df[product_df['product_length_cm'].isna()]

product_df = product_df.dropna()
product_df.isna().sum()

order_item_df.order_id.count()

order_item_df.groupby('order_id').order_id.count().sort_values(ascending=False)

order_item_df.price.sum()

order_item_df.freight_value.sum()

item_product_df = pd.merge(
    left=order_item_df,
    right=product_df,
    how="left",
    left_on="product_id",
    right_on="product_id"
)

item_product_df.head()

item_product_df.groupby('product_category_name').price.sum().sort_values(ascending=False)

item_product_df.groupby('product_category_name').freight_value.sum().sort_values(ascending=False)

item_seller_df = pd.merge(
    left=order_item_df,
    right=seller_df,
    how="left",
    left_on="seller_id",
    right_on="seller_id"
)

item_seller_df.head()

item_seller_df.groupby(by="seller_city").seller_id.nunique().sort_values(ascending=False)

item_seller_df.groupby(by="seller_state").seller_id.nunique().sort_values(ascending=False)

order_payment_df.groupby(by="payment_type").order_id.nunique().sort_values(ascending=False)

order_payment_df[order_payment_df['payment_type'] == 'not_defined']

order_payment_df[order_payment_df['payment_value'] == 0]

order_payment_df.groupby(by="payment_type").agg({
    "order_id": "nunique",
    "payment_value":  ["min", "max"]
})

delivery_time = order_df["order_delivered_customer_date"] - order_df["order_purchase_timestamp"]
delivery_time = delivery_time.apply(lambda x: x.total_seconds())
order_df["delivery_time"] = round(delivery_time/86400)

order_df.head()

order_df['delivery_time'].describe()

order_df[order_df['delivery_time'] == 210 ]

order_df['delivery_status'] = order_df.apply(
    lambda row: 'on time' if row['order_delivered_customer_date'] <= row['order_estimated_delivery_date'] else 'late', axis=1
)

order_df.head()

order_df['delivery_status'].describe()

order_df.groupby(by="delivery_status").delivery_status.count().sort_values(ascending=False)

customer_id_in_orders_df =  order_df.customer_id.tolist()
customer_df["status"] = customer_df["customer_id"].apply(lambda x: "Active" if x in customer_id_in_orders_df else "Non Active")
customer_df.head()

customer_df.groupby(by="status").customer_id.count()

order_customer_df = pd.merge(
    left=order_df,
    right=customer_df,
    how="left",
    left_on="customer_id",
    right_on="customer_id"
)
order_customer_df.head()

order_customer_df.groupby(by="customer_city").order_id.nunique().sort_values(ascending=False).reset_index().head(10)

order_customer_df.groupby(by="customer_state").order_id.nunique().sort_values(ascending=False).reset_index().head(10)

products_df = pd.merge(
    left=product_df,
    right=product_category_df,
    how="left",
    left_on="product_category_name",
    right_on="product_category_name"
)
products_df.head()

products_df.groupby(by="product_category_name").product_id.nunique().sort_values(ascending=False)

products_df.groupby(by="product_category_name_english").product_id.nunique().sort_values(ascending=False)

seller_product_df = pd.merge(
    left=products_df,
    right=item_seller_df,
    how="left",
    left_on="product_id",
    right_on="product_id"
)
seller_product_df.head()

seller_product_df.sort_values(by="price", ascending=False)

seller_product_df.groupby(by="product_category_name_english").agg({
    "product_id": "nunique",
    "order_item_id": "count",
    "price": ["min", "max"]
})

seller_product_df.groupby(by="product_category_name_english").agg({
    "order_id": "nunique",
    "order_item_id": "count",
    "price": "sum"
}).sort_values(by="price", ascending=False)

seller_product_df.groupby(by="product_category_name_english").agg({
    "order_id": "nunique",
    "order_item_id": "count",
    "price": "sum"
}).sort_values(by="order_item_id", ascending=False)

all_df= pd.merge(customer_df, order_df, on="customer_id")
all_df= all_df.merge(order_review_df, on="order_id")
all_df= all_df.merge(order_item_df, on="order_id")
all_df= all_df.merge(product_df, on="product_id")
all_df= all_df.merge(order_payment_df, on="order_id")
all_df= all_df.merge(seller_df, on='seller_id')
all_df= all_df.merge(product_category_df, on='product_category_name')
all_df.head()

all_df.info()

all_df.groupby(by=["customer_city", "product_category_name_english"]).agg({
    "price": "sum",
    "freight_value": "sum"
})

all_df.groupby(by=["customer_state", "product_category_name_english"]).agg({
    "price": "sum",
    "freight_value": "sum"
})

all_df.groupby(by="customer_city").agg({
    "order_id": "nunique",
    "payment_value": "sum"
}).sort_values(by="payment_value", ascending=False)

all_df.to_csv('all_df.csv', index=False)

sum_order_items_df = all_df.groupby("product_category_name_english").order_item_id.count().sort_values(ascending=False).reset_index()
sum_order_items_df

fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(24, 6))

colors = ["#72BF78", "#D3D3D3", "#D3D3D3", "#D3D3D3", "#D3D3D3"]

sns.barplot(x="order_item_id",
            y="product_category_name_english",
            data=sum_order_items_df.head(5),
            palette=colors,
            ax=ax[0])

ax[0].set_ylabel("Product Category", fontsize=12)
ax[0].set_xlabel("Number of Sales (Order Item)", fontsize=12)
ax[0].set_title("Best Performing Product", loc="center", fontsize=15)
ax[0].tick_params(axis='y', labelsize=12)

sns.barplot(x="order_item_id",
            y="product_category_name_english",
            data=sum_order_items_df.sort_values(by="order_item_id", ascending=True).head(5),
            palette=colors,
            ax=ax[1])

ax[1].set_ylabel("Product Category", fontsize=12)
ax[1].set_xlabel("Number of Sales (Order Item)", fontsize=12)
ax[1].invert_xaxis()
ax[1].yaxis.set_label_position("right")
ax[1].yaxis.tick_right()
ax[1].set_title("Worst Performing Product", loc="center", fontsize=15)
ax[1].tick_params(axis='y', labelsize=12)

plt.suptitle("Best and Worst Performing Product by Number of Sales", fontsize=20)

plt.tight_layout()
plt.show()

monthly_orders_df = all_df.resample(rule='M', on='order_purchase_timestamp').agg({
    "order_id": "nunique",
    "payment_value": "sum"
})
monthly_orders_df.index = monthly_orders_df.index.strftime('%Y-%m')
monthly_orders_df = monthly_orders_df.reset_index()
monthly_orders_df.rename(columns={
    "order_id": "order_count",
    "payment_value": "revenue"
}, inplace=True)
monthly_orders_df.head()

all_df = all_df.sort_values(by='order_purchase_timestamp')

monthly_performance = all_df.resample('M', on='order_purchase_timestamp').agg({
    "order_id": "nunique",
    "payment_value": "sum"
})

monthly_performance.index = monthly_performance.index.strftime('%B')
monthly_performance = monthly_performance.reset_index()

monthly_performance.rename(columns={
    "order_id": "order_count",
    "payment_value": "total_revenue"
}, inplace=True)

recent_months_performance = monthly_performance.tail(9)

plt.figure(figsize=(10, 5))
plt.plot(recent_months_performance["order_purchase_timestamp"],
         recent_months_performance["order_count"],
         marker='o', color='#72BF78', label='Number of Orders', linewidth=2)

# Menambahkan judul dan label
plt.title('Number of Orders in Recent Months (2018)', loc="center", fontsize=20)
plt.xlabel('Month', fontsize=12)
plt.ylabel('Number of Orders', fontsize=12)
plt.xticks(fontsize=10)
plt.yticks(fontsize=10)

plt.tight_layout()
plt.show()

plt.figure(figsize=(10, 5))
plt.plot(recent_months_performance["order_purchase_timestamp"],
         recent_months_performance["total_revenue"],
         marker='o', color='#72BF78', label='Revenue', linewidth=2)

plt.title('Revenue in Recent Months (2018)', loc="center", fontsize=20)
plt.xlabel('Month', fontsize=12)
plt.ylabel('Revenue', fontsize=12)
plt.xticks(fontsize=10)
plt.yticks(fontsize=10)

plt.tight_layout()
plt.show()

rfm_df = all_df.groupby(by="customer_unique_id", as_index=False).agg({
    "order_purchase_timestamp": "max",
    "order_id": "nunique",
    "payment_value": "sum"
})

rfm_df.columns = ["customer_unique_id", "max_order_timestamp", "frequency", "monetary"]

rfm_df["max_order_timestamp"] = pd.to_datetime(rfm_df["max_order_timestamp"]).dt.date

recent_date = all_df["order_purchase_timestamp"].dt.date.max()

rfm_df["recency"] = rfm_df["max_order_timestamp"].apply(lambda x: (recent_date - x).days)

rfm_df.drop("max_order_timestamp", axis=1, inplace=True)

rfm_df.head()

rfm_df.sort_values(by="frequency", ascending=False)

rfm_df.sort_values(by="monetary", ascending=False)

rfm_df.sort_values(by="recency", ascending=True)

fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(30, 6))

colors = ["#72BF78", "#72BF78", "#72BF78", "#72BF78", "#72BF78"]

sns.barplot(y="recency", x="customer_unique_id", data=rfm_df.sort_values(by="recency", ascending=True).head(5), palette=colors, ax=ax[0])
ax[0].set_ylabel(None)
ax[0].set_xlabel(None)
ax[0].set_title("By Recency (days)", loc="center", fontsize=18)
ax[0].tick_params(axis ='x', labelsize=15)
plt.setp(ax[0].get_xticklabels(), rotation=90)

sns.barplot(y="frequency", x="customer_unique_id", data=rfm_df.sort_values(by="frequency", ascending=False).head(5), palette=colors, ax=ax[1])
ax[1].set_ylabel(None)
ax[1].set_xlabel(None)
ax[1].set_title("By Frequency", loc="center", fontsize=18)
ax[1].tick_params(axis='x', labelsize=15)
plt.setp(ax[1].get_xticklabels(), rotation=90)

sns.barplot(y="monetary", x="customer_unique_id", data=rfm_df.sort_values(by="monetary", ascending=False).head(5), palette=colors, ax=ax[2])
ax[2].set_ylabel(None)
ax[2].set_xlabel(None)
ax[2].set_title("By Monetary", loc="center", fontsize=18)
ax[2].tick_params(axis='x', labelsize=15)
plt.setp(ax[2].get_xticklabels(), rotation=90)

plt.suptitle("Best Customer Based on RFM Parameters (customer_unique_id)", fontsize=20)
plt.show()

geolocation_state = geolocation_df.groupby(['geolocation_zip_code_prefix'])['geolocation_state'].nunique().reset_index(name='count')
geolocation_state[geolocation_state['count']>= 2].shape
max_state = geolocation_df.groupby(['geolocation_zip_code_prefix','geolocation_state']).size().reset_index(name='count').drop_duplicates(subset = 'geolocation_zip_code_prefix').drop('count',axis=1)

geolocation_spatial = geolocation_df.groupby(['geolocation_zip_code_prefix','geolocation_city','geolocation_state'])[['geolocation_lat','geolocation_lng']].median().reset_index()
geolocation_spatial = geolocation_spatial.merge(max_state,on=['geolocation_zip_code_prefix','geolocation_state'],how='inner')

customers_geo_spat = customer_df.merge(geolocation_spatial,left_on='customer_zip_code_prefix',right_on='geolocation_zip_code_prefix',how='inner')

customers_geo_spat.head()

customers_geo_spat.to_csv("geolocation.csv", index=False)

def plot_brazil_map(data):
    brazil = mpimg.imread(urllib.request.urlopen('https://i.pinimg.com/originals/3a/0c/e1/3a0ce18b3c842748c255bc0aa445ad41.jpg'),'jpg')
    ax = data.plot(kind="scatter", x="geolocation_lng", y="geolocation_lat", figsize=(10,10), alpha=0.3,s=0.3,c='green')
    plt.axis('off')
    plt.imshow(brazil, extent=[-73.98283055, -33.8,-33.75116944,5.4])
    plt.show()

plot_brazil_map(customers_geo_spat.drop_duplicates(subset='customer_unique_id'))

"""## Conclusion

- Produk dengan penjualan tertinggi termasuk kategori bed_bath_table, health_beauty, sports_leisure, furniture_decor, dan computers_accessories, sedangkan yang terendah berada di kategori security_and_services, fashion_childrens_clothes, cds_dvds_musicals, la_cuisine, dan arts_and_craftmanship.

- Selama tahun 2018, penjualan mengalami fluktuasi. Dari Januari ke Februari terjadi penurunan, kemudian meningkat dari Februari ke Maret. Dari Maret hingga Mei terjadi sedikit penurunan, lalu penjualan mengalami penurunan signifikan dari Mei ke Juni, sebelum akhirnya meningkat kembali dari Juli hingga Agustus.

- Begitu pula dengan pendapatan pada tahun 2018, yang juga menunjukkan tren naik turun. Pendapatan turun dari Januari ke Februari, kemudian melonjak signifikan dari Februari ke Maret. Dari Maret sampai Mei, pendapatan cenderung naik sedikit atau stabil, namun turun drastis dari Mei ke Juni. Dari Juni ke Juli terjadi kenaikan ringan, tetapi kembali turun pada bulan Agustus.

- Waktu terakhir pelanggan melakukan pembelian bervariasi, mulai dari yang terjadi hari ini (0 hari yang lalu), 5 hari yang lalu, hingga yang paling lama yaitu 729 hari yang lalu. Jumlah transaksi per pelanggan berkisar antara 1 kali hingga 15 kali, dengan total pengeluaran yang paling sedikit mencapai 9.59 dan yang paling banyak 109312.64.

- Selain itu, negara bagian dengan jumlah pelanggan terbanyak adalah SP, dan kota dengan pelanggan terbanyak adalah Sao Paulo.
"""